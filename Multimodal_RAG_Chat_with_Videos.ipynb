{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Multimodal RAG**"
      ],
      "metadata": {
        "id": "yvfnp5FjQoiY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lU09zl3V3VYm"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "pip install -U langchain-huggingface  langchain_community youtube-transcript-api LanceDB sentence-transformers faiss-gpu gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "-eNmHq2A_2Wq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load models\n",
        "print(\"Loading models...\")\n",
        "llm_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\", device=0)\n",
        "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "print(\"Models loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Pi_DyZ-05G",
        "outputId": "497f7439-3ba5-4487-ea47-028826d7403e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n",
            "<ipython-input-3-cd1ecdbd84ee>:4: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
            "<ipython-input-3-cd1ecdbd84ee>:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Helper Functions"
      ],
      "metadata": {
        "id": "Sd6Ipubt_IYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_youtube_transcript(video_url):\n",
        "    \"\"\"Fetch transcript from YouTube video.\"\"\"\n",
        "    video_id = video_url.split(\"v=\")[-1]\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        text = \" \".join([entry[\"text\"] for entry in transcript])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching transcript: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    video_url = input(\"Enter YouTube video URL: \").strip()\n",
        "    transcript = fetch_youtube_transcript(video_url)\n",
        "\n",
        "    if not transcript:\n",
        "        print(\"Unable to fetch transcript. Exiting...\")\n",
        "        return\n",
        "\n",
        "\n",
        "    transcript_docs = [transcript]\n",
        "    vector_store = FAISS.from_texts(transcript_docs, embeddings)\n",
        "\n",
        "    print(\"You can start asking questions about the video. Type 'quit' or 'exit' to end.\")\n",
        "\n",
        "    while True:\n",
        "        query = input(\"Ask a question: \").strip()\n",
        "        if query.lower() in [\"quit\", \"exit\"]:\n",
        "            print(\"Exiting. Goodbye!\")\n",
        "            break\n",
        "\n",
        "\n",
        "       # Retriever\n",
        "        docs = vector_store.similarity_search(query, k=5)\n",
        "\n",
        "        if not docs:\n",
        "            print(\"The question doesn't seem relevant to the video content. Try rephrasing.\")\n",
        "            continue\n",
        "\n",
        "\n",
        "        context = \" \".join([doc.page_content for doc in docs])         # Combine the retrieved docs into a single context\n",
        "        print(f\"Debug Context: {context}\")\n",
        "\n",
        "\n",
        "        prompt_template = PromptTemplate(\n",
        "            input_variables=[\"context\", \"query\"],\n",
        "            template=\"You are an assistant answering questions based on the following video transcript:\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\",\n",
        "        )\n",
        "        chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "        try:\n",
        "            response = chain.run({\"context\": context, \"query\": query})\n",
        "            print(f\"Response: {response}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrdiNvij31lh",
        "outputId": "49dd2f0b-6156-406e-bc4a-2aa71b6c473e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter YouTube video URL: https://www.youtube.com/watch?v=7Hcg-rLYwdM\n",
            "You can start asking questions about the video. Type 'quit' or 'exit' to end.\n",
            "Ask a question: What do the astronauts feel about their work?\n",
            "Debug Context: As I look back on the the mission that we've had here on the International Space Station,\n",
            "I'm proud to have been a part of much of the science activities that happened over the last two months. The view is always amazing I didn't think I would do another spacewalk and to now have the chance to have done four more was just icing on the cake for a a wonderful mission. Does the 10th one feel like the first one? No, a little more comfortable on the tenth one. It's hard to put into words just what it was like to be a part of\n",
            "this expedition, expedition 63. It'll be kind of a memory that will last a lifetime for me. It's been a true honor. Dragon SpaceX undock sequence commanded. Thrusters\n",
            "looking good. The hardest part was getting us launched, but the most important part is bringing us home. Rise and shine Daddy. We love you. Hurry home so we can go get my dog. Splashdown! Welcome back to planet Earth and thanks for flying SpaceX. It's truly our honor and privilege. Space Dads are back on Earth after a 19-hour return journey from space.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-5a52042c5ee2>:49: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt_template)\n",
            "<ipython-input-4-5a52042c5ee2>:52: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain.run({\"context\": context, \"query\": query})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: They feel proud\n",
            "Ask a question: what happend in the video?\n",
            "Debug Context: As I look back on the the mission that we've had here on the International Space Station,\n",
            "I'm proud to have been a part of much of the science activities that happened over the last two months. The view is always amazing I didn't think I would do another spacewalk and to now have the chance to have done four more was just icing on the cake for a a wonderful mission. Does the 10th one feel like the first one? No, a little more comfortable on the tenth one. It's hard to put into words just what it was like to be a part of\n",
            "this expedition, expedition 63. It'll be kind of a memory that will last a lifetime for me. It's been a true honor. Dragon SpaceX undock sequence commanded. Thrusters\n",
            "looking good. The hardest part was getting us launched, but the most important part is bringing us home. Rise and shine Daddy. We love you. Hurry home so we can go get my dog. Splashdown! Welcome back to planet Earth and thanks for flying SpaceX. It's truly our honor and privilege. Space Dads are back on Earth after a 19-hour return journey from space.\n",
            "Response: The 10th spacewalk was a great experience\n",
            "Ask a question: what is the video talking about?\n",
            "Debug Context: As I look back on the the mission that we've had here on the International Space Station,\n",
            "I'm proud to have been a part of much of the science activities that happened over the last two months. The view is always amazing I didn't think I would do another spacewalk and to now have the chance to have done four more was just icing on the cake for a a wonderful mission. Does the 10th one feel like the first one? No, a little more comfortable on the tenth one. It's hard to put into words just what it was like to be a part of\n",
            "this expedition, expedition 63. It'll be kind of a memory that will last a lifetime for me. It's been a true honor. Dragon SpaceX undock sequence commanded. Thrusters\n",
            "looking good. The hardest part was getting us launched, but the most important part is bringing us home. Rise and shine Daddy. We love you. Hurry home so we can go get my dog. Splashdown! Welcome back to planet Earth and thanks for flying SpaceX. It's truly our honor and privilege. Space Dads are back on Earth after a 19-hour return journey from space.\n",
            "Response: Space Dads are back on Earth after a 19-hour return journey from space.\n",
            "Ask a question: quit\n",
            "Exiting. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried on this YouTube video:  \n",
        "[https://www.youtube.com/watch?v=7Hcg-rLYwdM](https://www.youtube.com/watch?v=7Hcg-rLYwdM)\n",
        "\n"
      ],
      "metadata": {
        "id": "yqahXwuD_Llq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio App"
      ],
      "metadata": {
        "id": "hyqsyf50GK8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_youtube_transcript(video_url):\n",
        "    video_id = video_url.split(\"v=\")[-1]\n",
        "    try:\n",
        "        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "        text = \" \".join([entry[\"text\"] for entry in transcript])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching transcript: {e}\"\n",
        "\n",
        "\n",
        "def create_vector_store(transcript):\n",
        "    transcript_docs = [transcript]\n",
        "    return FAISS.from_texts(transcript_docs, embeddings)\n",
        "\n",
        "\n",
        "def process_query(video_url, query):\n",
        "    transcript = fetch_youtube_transcript(video_url)\n",
        "    if \"Error\" in transcript:\n",
        "        return transcript, \"\"\n",
        "\n",
        "    vector_store = create_vector_store(transcript)\n",
        "\n",
        "    docs = vector_store.similarity_search(query, k=5)\n",
        "\n",
        "    if not docs:\n",
        "        return \"No relevant context found for your query.\", \"\"\n",
        "\n",
        "    context = \" \".join([doc.page_content for doc in docs])\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"context\", \"query\"],\n",
        "        template=\"You are an assistant answering questions based on the following video transcript:\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\",\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "\n",
        "    try:\n",
        "        response = chain.run({\"context\": context, \"query\": query})\n",
        "        return response, video_url\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\", video_url\n"
      ],
      "metadata": {
        "id": "vEoodHL3FgVu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_interface(video_url, query):\n",
        "    response, video_display = process_query(video_url, query)\n",
        "    video_embed = f'<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/{video_url.split(\"v=\")[-1]}\" frameborder=\"0\" allowfullscreen></iframe>'\n",
        "    return response, video_embed\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    body {\n",
        "        background-color:black !important; /* Ensures the black background is applied */\n",
        "        color: white !important; /* Ensures text is white */\n",
        "    }\n",
        "    button {\n",
        "        background-color: #1a73e8 !important; /* Blue buttons */\n",
        "        color: black !important; /* Button text color */\n",
        "    }\n",
        "    button:hover {\n",
        "        background-color: green !important; /* Darker blue on hover */\n",
        "    }\n",
        "\"\"\") as app:\n",
        "    gr.Markdown(\"Chat with YouTube Video\")\n",
        "    with gr.Row():\n",
        "        video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the video URL here\")\n",
        "    with gr.Row():\n",
        "        query = gr.Textbox(label=\"Ask a Question\", placeholder=\"Ask something about the video transcript\")\n",
        "    with gr.Row():\n",
        "        response = gr.Textbox(label=\"Response\", placeholder=\"The assistant's response will appear here\", interactive=False)\n",
        "    with gr.Row():\n",
        "        video_display = gr.HTML(value=\"\")\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"Submit\")\n",
        "\n",
        "    submit_btn.click(main_interface, inputs=[video_url, query], outputs=[response, video_display])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.launch()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Dj1ydoUXFpW_",
        "outputId": "56377734-0fb2-4a19-fe5f-008f44690b28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://461259201c50425ad7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://461259201c50425ad7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}